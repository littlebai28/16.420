{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“hw07.ipynb”的副本",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVPxokApp3To"
      },
      "source": [
        "# Homework 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGoEz_ovp3Ts"
      },
      "source": [
        "## Imports and Utilities\n",
        "**Note**: these imports and functions are available in catsoop. You do not need to copy them in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU55M6-Vp3Tt"
      },
      "source": [
        "from collections import defaultdict\n",
        "import abc\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class MDP:\n",
        "    \"\"\"A Markov Decision Process.\"\"\"\n",
        "\n",
        "    @property\n",
        "    @abc.abstractmethod\n",
        "    def state_space(self):\n",
        "        \"\"\"Representation of the MDP state set.\n",
        "\n",
        "        Unless otherwise stated, assume this is a set.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"Override me\")\n",
        "\n",
        "    @property\n",
        "    @abc.abstractmethod\n",
        "    def action_space(self):\n",
        "        \"\"\"Representation of the MDP action set.\n",
        "\n",
        "        Unless otherwise stated, assume this is a set.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"Override me\")\n",
        "\n",
        "    @property\n",
        "    def temporal_discount_factor(self):\n",
        "        \"\"\"Gamma, defaults to 1.\n",
        "        \"\"\"\n",
        "        return 1.\n",
        "\n",
        "    @property\n",
        "    def horizon(self):\n",
        "        \"\"\"H, defaults to inf.\n",
        "        \"\"\"\n",
        "        return float(\"inf\")\n",
        "\n",
        "    def state_is_terminal(self, state):\n",
        "        \"\"\"Designate certain states as terminal (done) states.\n",
        "\n",
        "        Defaults to False.\n",
        "\n",
        "        Args:\n",
        "            state: A state.\n",
        "\n",
        "        Returns:\n",
        "            is_terminal : A bool.\n",
        "        \"\"\"\n",
        "        return False\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def get_reward(self, state, action, next_state):\n",
        "        \"\"\"Return (deterministic) reward for executing action\n",
        "        in state.\n",
        "\n",
        "        Args:\n",
        "            state: A current state.\n",
        "            action: An action.\n",
        "            next_state: A next state.\n",
        "\n",
        "        Returns:\n",
        "            reward : Single time step reward.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"Override me\")\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def get_transition_distribution(self, state, action):\n",
        "        \"\"\"Return a distribution over next states.\n",
        "\n",
        "        Unless otherwise stated, assume that this returns\n",
        "        a dictionary mapping states to probabilities. For\n",
        "        example, if the state space were {0, 1, 2}, then\n",
        "        this function might return {0: 0.3, 1: 0.2, 2: 0.5}.\n",
        "\n",
        "        Args:\n",
        "            state: A current state.\n",
        "            action: An action.\n",
        "\n",
        "        Returns:\n",
        "            next_state_distribution: Distribution over next states.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"Override me\")\n",
        "\n",
        "    def sample_next_state(self, state, action, rng=np.random):\n",
        "        \"\"\"Sample a next state from the transition distribution.\n",
        "\n",
        "        This function may be overwritten by subclasses when the explicit\n",
        "        distribution is too large to enumerate.\n",
        "\n",
        "        Args:\n",
        "            state: A state from the state space.\n",
        "            action: An action from the action space.\n",
        "            rng: A random number generator.\n",
        "\n",
        "        Returns:\n",
        "            next_state: A sampled next state from the state space.\n",
        "        \"\"\"\n",
        "        next_state_dist = self.get_transition_distribution(state, action)\n",
        "        next_states, probs = zip(*next_state_dist.items())\n",
        "        next_state_index = rng.choice(len(next_states), p=probs)\n",
        "        next_state = next_states[next_state_index]\n",
        "        return next_state\n",
        "\n",
        "\n",
        "class SingleRowMDP(MDP):\n",
        "    \"\"\"A 1D grid MDP for debugging. The grid is 1x5\n",
        "    and the agent is meant to start off in the middle.\n",
        "    There is +10 reward on the rightmost square, -10 on\n",
        "    the left. Actions are left and right. An action effect\n",
        "    is reversed with 10% probability.\n",
        "    \"\"\"\n",
        "    @property\n",
        "    def state_space(self):\n",
        "        return {0, 1, 2, 3, 4}  # position in grid\n",
        "\n",
        "    @property\n",
        "    def action_space(self):\n",
        "        return {0, 1}  # left, right\n",
        "\n",
        "    def get_transition_distribution(self, state, action):\n",
        "        # Discrete distributions, represented with a dict\n",
        "        # mapping next states to probs.\n",
        "        delta = 1 if action == 1 else -1\n",
        "        intended_effect = min(max(state + delta, 0), 4)\n",
        "        opposite_effect = min(max(state - delta, 0), 4)\n",
        "        assert (intended_effect != opposite_effect)\n",
        "        return {intended_effect: 0.9, opposite_effect: 0.1}\n",
        "\n",
        "    def get_reward(self, state, action, next_state):\n",
        "        if next_state == 0:\n",
        "          return -10\n",
        "        if next_state == 4:\n",
        "          return 10\n",
        "        return -1  # living penalty\n",
        "\n",
        "    def state_is_terminal(self, state):\n",
        "        return state in {0, 4}\n",
        "\n",
        "\n",
        "class MarshmallowMDP(MDP):\n",
        "    \"\"\"The Marshmallow MDP described in lecture.\"\"\"\n",
        "\n",
        "    @property\n",
        "    def state_space(self):\n",
        "        # (hunger level, marshmallow remains)\n",
        "        return {(h, m) for h in {0, 1, 2} for m in {True, False}}\n",
        "\n",
        "    @property\n",
        "    def action_space(self):\n",
        "        return {\"eat\", \"wait\"}\n",
        "\n",
        "    @property\n",
        "    def horizon(self):\n",
        "        return 4\n",
        "\n",
        "    def get_reward(self, state, action, next_state):\n",
        "        next_hunger_level = next_state[0]\n",
        "        return -(next_hunger_level**2)\n",
        "\n",
        "    def get_transition_distribution(self, state, action):\n",
        "        # Update marshmallow deterministically\n",
        "        if action == \"eat\":\n",
        "            next_m = False\n",
        "        else:\n",
        "            next_m = state[1]\n",
        "\n",
        "        # Initialize next state distribution dict\n",
        "        # Any state not included assumed to have 0 prob\n",
        "        dist = defaultdict(float)\n",
        "\n",
        "        # Update hunger\n",
        "        if action == \"wait\" or state[1] == False:\n",
        "            # With 0.75 probability, hunger stays the same\n",
        "            dist[(state[0], next_m)] += 0.75\n",
        "            # With 0.25 probability, hunger increases by 1\n",
        "            dist[(min(state[0] + 1, 2), next_m)] += 0.25\n",
        "\n",
        "        else:\n",
        "            assert action == \"eat\" and state[1] == True\n",
        "            # Hunger deterministically set to 1 after eating\n",
        "            dist[(0, next_m)] = 1.0\n",
        "\n",
        "        return dist\n",
        "\n",
        "\n",
        "class ZitsMDP(MDP):\n",
        "    \"\"\"The Zits MDP described in lecture.\"\"\"\n",
        "    \n",
        "    @property\n",
        "    def state_space(self):\n",
        "        return {0, 1, 2, 3, 4}\n",
        "\n",
        "    @property\n",
        "    def action_space(self):\n",
        "        return {\"apply\", \"sleep\"}\n",
        "\n",
        "    @property\n",
        "    def temporal_discount_factor(self):\n",
        "        return 0.9\n",
        "\n",
        "    def get_reward(self, state, action, next_state):\n",
        "        if action == \"apply\":\n",
        "            return -1 - next_state\n",
        "        assert action == \"sleep\"\n",
        "        return -next_state\n",
        "\n",
        "    def get_transition_distribution(self, state, action):\n",
        "        if action == \"apply\":\n",
        "            return {\n",
        "                0: 0.8,\n",
        "                4: 0.2\n",
        "            }\n",
        "        assert action == \"sleep\"\n",
        "        return {\n",
        "            min(state + 1, 4): 0.4,\n",
        "            max(state - 1, 0): 0.6\n",
        "        }\n",
        "\n",
        "\n",
        "class ChaseMDP(MDP):\n",
        "    \"\"\"A 2D grid bunny chasing MDP.\"\"\"\n",
        "\n",
        "    @property\n",
        "    def obstacles(self):\n",
        "        return np.zeros((2, 3))  # by default, 2x3 grid with no obstacles\n",
        "\n",
        "    @property\n",
        "    def goal_reward(self):\n",
        "        return 1\n",
        "\n",
        "    @property\n",
        "    def living_reward(self):\n",
        "        return 0\n",
        "\n",
        "    @property\n",
        "    def height(self):\n",
        "        return self.obstacles.shape[0]\n",
        "\n",
        "    @property\n",
        "    def width(self):\n",
        "        return self.obstacles.shape[1]\n",
        "\n",
        "    @property\n",
        "    def state_space(self):\n",
        "        pos = [(r, c) for r in range(self.height) for c in range(self.width)]\n",
        "        return {(p1, p2) for p1 in pos for p2 in pos}\n",
        "\n",
        "    @property\n",
        "    def action_space(self):\n",
        "        return {'up', 'down', 'left', 'right'}\n",
        "\n",
        "    @property\n",
        "    def temporal_discount_factor(self):\n",
        "        return 0.9\n",
        "\n",
        "    def action_to_delta(self, action):\n",
        "        return {\n",
        "            'up': (-1, 0),  # up,\n",
        "            'down': (1, 0),  # down,\n",
        "            'left': (0, -1),  # left,\n",
        "            'right': (0, 1),  # right,\n",
        "        }[action]\n",
        "\n",
        "    def get_transition_distribution(self, state, action):\n",
        "        # Discrete distributions, represented with a dict\n",
        "        # mapping next states to probs.\n",
        "        next_state_dist = defaultdict(float)\n",
        "\n",
        "        agent_pos, goal_pos = state\n",
        "\n",
        "        # Get next agent state\n",
        "        row, col = agent_pos\n",
        "        dr, dc = self.action_to_delta(action)\n",
        "        r, c = row + dr, col + dc\n",
        "        # Stay in place if out of bounds or obstacle\n",
        "        if not (0 <= r < self.height and 0 <= c < self.width):\n",
        "            r, c = row, col\n",
        "        elif self.obstacles[r, c]:\n",
        "            r, c = row, col\n",
        "        next_agent_pos = (r, c)\n",
        "\n",
        "        # Get next bunny state\n",
        "        # Stay in same place with probability 0.5\n",
        "        next_state_dist[(next_agent_pos, goal_pos)] += 0.5\n",
        "        # Otherwise move\n",
        "        row, col = goal_pos\n",
        "        for (dr, dc) in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n",
        "            r, c = row + dr, col + dc\n",
        "            # Stay in place if out of bounds or obstacle\n",
        "            if not (0 <= r < self.height and 0 <= c < self.width):\n",
        "                r, c = row, col\n",
        "            elif self.obstacles[r, c]:\n",
        "                r, c = row, col\n",
        "            next_goal_pos = (r, c)\n",
        "            next_state_dist[(next_agent_pos, next_goal_pos)] += 0.5*0.25\n",
        "\n",
        "        return next_state_dist\n",
        "\n",
        "    def get_reward(self, state, action, next_state):\n",
        "        agent_pos, goal_pos = next_state\n",
        "        if agent_pos == goal_pos:\n",
        "            return self.goal_reward\n",
        "        return self.living_reward\n",
        "\n",
        "    def state_is_terminal(self, state):\n",
        "        agent_pos, goal_pos = state\n",
        "        return agent_pos == goal_pos\n",
        "\n",
        "\n",
        "class LargeChaseMDP(ChaseMDP):\n",
        "    \"\"\"A larger 2D grid bunny chasing MDP.\"\"\"\n",
        "\n",
        "    @property\n",
        "    def obstacles(self):\n",
        "        return np.array([\n",
        "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "            [0, 0, 0, 1, 0, 0, 0, 0, 1, 1],\n",
        "            [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
        "            [0, 1, 0, 1, 1, 0, 1, 0, 0, 0],\n",
        "            [0, 0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
        "            [0, 1, 1, 0, 0, 0, 0, 1, 1, 0],\n",
        "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "        ])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZhnmxzrp3Tz"
      },
      "source": [
        "## Problems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAj6nMEtp3T0"
      },
      "source": [
        "### Wait, Bellman, Backup!\n",
        "Complete the implementation of the bellman backup for an infinite or indefinite horizon MDP.\n",
        "\n",
        "For reference, our solution is **12** lines of code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnWcQR2qp3T0"
      },
      "source": [
        "def bellman_backup(s, V, mdp):\n",
        "  \"\"\"Look ahead one step and propose an update for the value of s.\n",
        "\n",
        "  You can assume that the mdp is either infinite or indefinite\n",
        "  horizon (that is, mdp.horizon is inf).\n",
        "\n",
        "  It is possible to handle terminal states either here or in\n",
        "  value iteration. For consistency with our solution, please\n",
        "  handle terminal states in value iteration, not here.\n",
        "\n",
        "  Args:\n",
        "      s: A state.\n",
        "      V: A dict, V[state] -> value.\n",
        "      mdp: An MDP.\n",
        "\n",
        "  Returns:\n",
        "      vs: new value estimate for s.\n",
        "  \"\"\"\n",
        "  re = -1000\n",
        "  for a in mdp.action_space:\n",
        "    temp = 0\n",
        "    t = mdp.get_transition_distribution(s, a)\n",
        "    for next in t.keys():\n",
        "      p = t[next]\n",
        "      r = mdp.get_reward(s,a,next)\n",
        "      temp += p*(r+mdp.temporal_discount_factor*V[next])\n",
        "    re = max(re,temp)\n",
        "  return re\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Sh7uNbgp3T1"
      },
      "source": [
        "Tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJrZ67F9p3T2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d298a8be-f0a2-4018-a30b-af7341835de0"
      },
      "source": [
        "def test1_bellman_backup():\n",
        "    mdp = SingleRowMDP()\n",
        "    s = 3\n",
        "    V = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}\n",
        "    new_V_s = bellman_backup(s, V, mdp)\n",
        "    # Bellman backup should not change V\n",
        "    assert V == {0: 0, 1: 0, 2: 0, 3: 0, 4: 0}\n",
        "    assert new_V_s == 0.9 * 10 + 0.1 * -1\n",
        "    s = 2\n",
        "    new_V_s = bellman_backup(s, V, mdp)\n",
        "    assert new_V_s == -1.\n",
        "\n",
        "test1_bellman_backup()\n",
        "def test2_bellman_backup():\n",
        "    mdp = ZitsMDP()\n",
        "    V = {s : 0 for s in mdp.state_space}\n",
        "    assert bellman_backup(0, V, mdp) == -0.4\n",
        "    assert bellman_backup(1, V, mdp) == -0.8\n",
        "    assert bellman_backup(2, V, mdp) == -1.8\n",
        "    assert bellman_backup(3, V, mdp) == -1.8\n",
        "    assert bellman_backup(4, V, mdp) == -1.8\n",
        "\n",
        "test2_bellman_backup()\n",
        "def test3_bellman_backup():\n",
        "    mdp = ZitsMDP()\n",
        "    V = {0 : -0.1, 1: 0.1, 2: 5, 3: -4, 4: -2.2}\n",
        "    assert abs(bellman_backup(0, V, mdp) - -0.418) < 1e-5\n",
        "    assert abs(bellman_backup(1, V, mdp) - 0.946) < 1e-5\n",
        "    assert abs(bellman_backup(2, V, mdp) - -2.268) < 1e-5\n",
        "    assert abs(bellman_backup(3, V, mdp) - -0.892) < 1e-5\n",
        "    assert abs(bellman_backup(4, V, mdp) - -2.268) < 1e-5\n",
        "\n",
        "test3_bellman_backup()\n",
        "print('Tests passed.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tests passed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYis4mkOp3T3"
      },
      "source": [
        "### There's Value in that Iteration\n",
        "Complete the implementation of value iteration for an infinite or indefinite horizon MDP.\n",
        "\n",
        "For reference, our solution is **19** lines of code.\n",
        "\n",
        "In addition to all of the utilities defined at the top of the colab notebook, the following functions are available in this question environment: `bellman_backup`. You may not need to use all of them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8DZnoRyp3T4"
      },
      "source": [
        "def value_iteration(mdp, max_num_iters=1000, change_threshold=0.0001):\n",
        "  \"\"\"Run value iteration for a certain number of iterations or until\n",
        "  the max change between iterations is below a threshold.\n",
        "\n",
        "  Specifically, you should terminate when:\n",
        "      (max_{s} |V(s) - V'(s)|) < change_threshold\n",
        "  where V is the old value function estimate, V' is the new one,\n",
        "  and |*| denotes absolute value.\n",
        "\n",
        "  You can assume that the mdp is either infinite or indefinite\n",
        "  horizon (that is, mdp.horizon is inf).\n",
        "\n",
        "  Make sure to handle terminal states! You will need to think about\n",
        "  what behavior we should expect from value iteration exactly to\n",
        "  deal with terminal states, and then implement that behavior.\n",
        "\n",
        "  Args:\n",
        "      mdp: An MDP.\n",
        "      max_num_iters: An int representing the maximum number of\n",
        "          iterations to run value iteration before giving up.\n",
        "      change_threshold: A float used to determine when value iteration\n",
        "          has converged and it is safe to terminate.\n",
        "\n",
        "  Returns: \n",
        "      V:  A dict, V[state] -> value.\n",
        "  \"\"\"\n",
        "  values = {}\n",
        "  no_terminal_state = set()\n",
        "  for s in mdp.state_space:\n",
        "    if not mdp.state_is_terminal(s):\n",
        "      no_terminal_state.add(s)\n",
        "  for s in mdp.state_space:\n",
        "    values[s] = 0\n",
        "  for _ in range(max_num_iters):\n",
        "    new_val = {}\n",
        "    changed = False\n",
        "    for s in no_terminal_state:\n",
        "      #print(bellman_backup(s,values,mdp))\n",
        "      new_val[s] = bellman_backup(s,values,mdp)\n",
        "      if abs(new_val[s] - values[s]) >= change_threshold: changed = True\n",
        "    for s in no_terminal_state:\n",
        "      values[s] = new_val[s]\n",
        "    print(values)\n",
        "    if not changed:\n",
        "      #print(values)\n",
        "      return values\n",
        "    \n",
        "  print(values)\n",
        "  return values\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhrX2vTUp3T5"
      },
      "source": [
        "Tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-iT-SUtp3T5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4583ed7a-cdeb-4c2f-902c-9e69b91d2c16"
      },
      "source": [
        "def test1_value_iteration():\n",
        "    mdp = SingleRowMDP()\n",
        "    V = value_iteration(mdp)\n",
        "    expected_V = {0: 0.0, 1: 5.58531, 2: 8.31706, 3: 9.73170, 4: 0.0}\n",
        "    for s in mdp.state_space:\n",
        "        assert abs(V[s] - expected_V[s]) < 1e-4\n",
        "\n",
        "test1_value_iteration()#{0,1}\n",
        "def test2_value_iteration():\n",
        "    mdp = ZitsMDP()\n",
        "    V = value_iteration(mdp)\n",
        "    expected_V = {0: -6.40530, 1: -7.07368, 2: -7.81918, 3: -7.81918, 4: -7.81918}\n",
        "    for s in mdp.state_space:\n",
        "        assert abs(V[s] - expected_V[s]) < 1e-4\n",
        "\n",
        "\n",
        "test2_value_iteration()#{'sleep', 'apply'}\n",
        "def test3_value_iteration():\n",
        "    mdp = SingleRowMDP()\n",
        "    expected_V = {0: 0.0, 1: -1.9, 2: -1.0, 3: 8.9, 4: 0.0}\n",
        "    V = value_iteration(mdp, max_num_iters=1)\n",
        "    for s in mdp.state_space:\n",
        "        assert abs(V[s] - expected_V[s]) < 1e-4\n",
        "    V = value_iteration(mdp, change_threshold=float(\"inf\"))\n",
        "    for s in mdp.state_space:\n",
        "        assert abs(V[s] - expected_V[s]) < 1e-4\n",
        "\n",
        "test3_value_iteration()#{0,1}\n",
        "def test4_value_iteration():\n",
        "    mdp = ChaseMDP()\n",
        "    V = value_iteration(mdp)\n",
        "    partial_expected_V = {((0, 1), (0, 1)): 0.0, ((0, 1), (1, 0)): 0.87506,\n",
        "                          ((1, 0), (0, 2)): 0.80601, ((0, 2), (1, 2)): 0.96536,\n",
        "                          ((1, 1), (0, 1)): 0.94896}\n",
        "    for s in partial_expected_V:\n",
        "        assert abs(V[s] - partial_expected_V[s]) < 1e-4\n",
        "\n",
        "test4_value_iteration()#{'up', 'left', 'right', 'down'}\n",
        "print('Tests passed.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 0, 1: -1.9, 2: -1.0, 3: 8.9, 4: 0}\n",
            "{0: 0, 1: -2.8, 2: 6.82, 3: 8.8, 4: 0}\n",
            "{0: 0, 1: 4.238, 2: 6.640000000000001, 3: 9.582, 4: 0}\n",
            "{0: 0, 1: 4.0760000000000005, 2: 8.047600000000001, 3: 9.564, 4: 0}\n",
            "{0: 0, 1: 5.342840000000001, 2: 8.0152, 3: 9.70476, 4: 0}\n",
            "{0: 0, 1: 5.313680000000001, 2: 8.268568, 3: 9.70152, 4: 0}\n",
            "{0: 0, 1: 5.5417112, 2: 8.262736, 3: 9.7268568, 4: 0}\n",
            "{0: 0, 1: 5.5364624000000005, 2: 8.30834224, 3: 9.7262736, 4: 0}\n",
            "{0: 0, 1: 5.577508016, 2: 8.307292480000001, 3: 9.730834224, 4: 0}\n",
            "{0: 0, 1: 5.576563232000001, 2: 8.315501603200001, 3: 9.730729248, 4: 0}\n",
            "{0: 0, 1: 5.583951442880001, 2: 8.315312646399999, 3: 9.73155016032, 4: 0}\n",
            "{0: 0, 1: 5.583781381759999, 2: 8.316790288576, 3: 9.73153126464, 4: 0}\n",
            "{0: 0, 1: 5.5851112597184, 2: 8.316756276351999, 3: 9.7316790288576, 4: 0}\n",
            "{0: 0, 1: 5.585080648716799, 2: 8.317022251943682, 3: 9.7316756276352, 4: 0}\n",
            "{0: 0, 1: 5.585320026749313, 2: 8.31701612974336, 3: 9.731702225194368, 4: 0}\n",
            "{0: 0, 1: 5.585314516769024, 2: 8.317064005349863, 3: 9.731701612974335, 4: 0}\n",
            "{0: -0.4, 1: -0.8, 2: -1.8, 3: -1.8, 4: -1.8}\n",
            "{0: -0.9040000000000001, 1: -1.6640000000000001, 2: -2.412, 3: -2.412, 4: -2.412}\n",
            "{0: -1.4872, 1: -2.15648, 2: -2.88504, 3: -2.88504, 4: -2.88504}\n",
            "{0: -1.9794208000000002, 1: -2.6417024000000002, 2: -3.3900912000000005, 3: -3.3900912000000005, 4: -3.3900912000000005}\n",
            "{0: -2.419900096, 1: -3.0893200640000007, 2: -3.8353993920000002, 3: -3.8353993920000002, 4: -3.8353993920000002}\n",
            "{0: -2.8189012748800004, 1: -3.4874898329600006, 2: -4.232699959680001, 3: -4.232699959680001, 4: -4.232699959680001}\n",
            "{0: -3.177703028300801, 1: -3.8459786739200004, 2: -4.591494910656001, 3: -4.591494910656001, 4: -4.591494910656001}\n",
            "{0: -3.5005119578936323, 1: -4.168897803118593, 2: -4.914415264294657, 3: -4.914415264294657, 4: -4.914415264294657}\n",
            "{0: -3.7910796663852553, 1: -4.459465952408638, 2: -5.204963357256454, 3: -5.204963357256454, 4: -5.204963357256454}\n",
            "{0: -4.052590762715147, 1: -4.720969828460362, 2: -5.466470764103546, 3: -5.466470764103546, 4: -5.466470764103546}\n",
            "{0: -4.2879481501119106, 1: -4.956328486943456, 2: -5.701830086693545, 3: -5.701830086693545, 4: -5.701830086693545}\n",
            "{0: -4.499770256360076, 1: -5.168150832270108, 2: -5.913652083685414, 3: -5.913652083685414, 4: -5.913652083685414}\n",
            "{0: -4.69041023805168, 1: -5.358790688561189, 2: -6.10429195964263, 3: -6.10429195964263, 4: -6.10429195964263}\n",
            "{0: -4.8619861764299355, 1: -5.530366634019255, 2: -6.275867924132884, 3: -6.275867924132884, 4: -6.275867924132884}\n",
            "{0: -5.016404523519097, 1: -5.684784987960004, 2: -6.430286273373473, 3: -6.430286273373473, 4: -6.430286273373473}\n",
            "{0: -5.155381038365914, 1: -5.823761501114762, 2: -6.569262786140975, 3: -6.569262786140975, 4: -6.569262786140975}\n",
            "{0: -5.280459901118908, 1: -5.948840363728345, 2: -6.694341649128834, 3: -6.694341649128834, 4: -6.694341649128834}\n",
            "{0: -5.393030877546415, 1: -6.061411340290591, 2: -6.806912625648804, 3: -6.806912625648804, 4: -6.806912625648804}\n",
            "{0: -5.494344756379677, 1: -6.1627252191086335, 2: -6.908226504450204, 3: -6.908226504450204, 4: -6.908226504450204}\n",
            "{0: -5.5855272473241335, 1: -6.253907710047099, 2: -6.999408995394404, 3: -6.999408995394404, 4: -6.999408995394404}\n",
            "{0: -5.667591489171988, 1: -6.335971951897018, 2: -7.081473237244369, 3: -7.081473237244369, 4: -7.081473237244369}\n",
            "{0: -5.741449306835801, 1: -6.4098297695608455, 2: -7.155331054907817, 3: -7.155331054907817, 4: -7.155331054907817}\n",
            "{0: -5.807921342733238, 1: -6.476301805458148, 2: -7.221803090805185, 3: -7.221803090805185, 4: -7.221803090805185}\n",
            "{0: -5.867746175040882, 1: -6.536126637765816, 2: -7.281627923112865, 3: -7.281627923112865, 4: -7.281627923112865}\n",
            "{0: -5.9215885241177695, 1: -6.589968986842708, 2: -7.335470272189751, 3: -7.335470272189751, 4: -7.335470272189751}\n",
            "{0: -5.97004663828697, 1: -6.638427101011906, 2: -7.383928386358949, 3: -7.383928386358949, 4: -7.383928386358949}\n",
            "{0: -6.01365894103925, 1: -6.682039403764184, 2: -7.427540689111229, 3: -7.427540689111229, 4: -7.427540689111229}\n",
            "{0: -6.052910013516302, 1: -6.721290476241238, 2: -7.466791761588282, 3: -7.466791761588282, 4: -7.466791761588282}\n",
            "{0: -6.088235978745649, 1: -6.756616441470585, 2: -7.5021177268176285, 3: -7.5021177268176285, 4: -7.5021177268176285}\n",
            "{0: -6.120029347452061, 1: -6.788409810176997, 2: -7.533911095524041, 3: -7.533911095524041, 4: -7.533911095524041}\n",
            "{0: -6.148643379287832, 1: -6.817023842012768, 2: -7.562525127359812, 3: -7.562525127359812, 4: -7.562525127359812}\n",
            "{0: -6.174396007940025, 1: -6.842776470664962, 2: -7.5882777560120065, 3: -7.5882777560120065, 4: -7.5882777560120065}\n",
            "{0: -6.197573373727, 1: -6.865953836451936, 2: -7.611455121798981, 3: -7.611455121798981, 4: -7.611455121798981}\n",
            "{0: -6.218433002935278, 1: -6.886813465660214, 2: -7.632314751007257, 3: -7.632314751007257, 4: -7.632314751007257}\n",
            "{0: -6.2372066692227275, 1: -6.905587131947663, 2: -7.651088417294707, 3: -7.651088417294707, 4: -7.651088417294707}\n",
            "{0: -6.254102968881432, 1: -6.922483431606368, 2: -7.667984716953411, 3: -7.667984716953411, 4: -7.667984716953411}\n",
            "{0: -6.269309638574265, 1: -6.937690101299202, 2: -7.683191386646246, 3: -7.683191386646246, 4: -7.683191386646246}\n",
            "{0: -6.282995641297816, 1: -6.951376104022751, 2: -7.696877389369796, 3: -7.696877389369796, 4: -7.696877389369796}\n",
            "{0: -6.295313043749012, 1: -6.963693506473947, 2: -7.709194791820991, 3: -7.709194791820991, 4: -7.709194791820991}\n",
            "{0: -6.306398705955088, 1: -6.974779168680024, 2: -7.720280454027067, 3: -7.720280454027067, 4: -7.720280454027067}\n",
            "{0: -6.316375801940556, 1: -6.984756264665492, 2: -7.730257550012537, 3: -7.730257550012537, 4: -7.730257550012537}\n",
            "{0: -6.325355188327478, 1: -6.993735651052415, 2: -7.7392369363994575, 3: -7.7392369363994575, 4: -7.7392369363994575}\n",
            "{0: -6.333436636075708, 1: -7.001817098800643, 2: -7.747318384147688, 3: -7.747318384147688, 4: -7.747318384147688}\n",
            "{0: -6.340709939049114, 1: -7.009090401774051, 2: -7.754591687121094, 3: -7.754591687121094, 4: -7.754591687121094}\n",
            "{0: -6.3472559117251794, 1: -7.015636374450116, 2: -7.76113765979716, 3: -7.76113765979716, 4: -7.76113765979716}\n",
            "{0: -6.353147287133639, 1: -7.021527749858575, 2: -7.767029035205619, 3: -7.767029035205619, 4: -7.767029035205619}\n",
            "{0: -6.3584495250012525, 1: -7.026829987726188, 2: -7.772331273073233, 3: -7.772331273073233, 4: -7.772331273073233}\n",
            "{0: -6.3632215390821045, 1: -7.03160200180704, 2: -7.777103287154084, 3: -7.777103287154084, 4: -7.777103287154084}\n",
            "{0: -6.367516351754871, 1: -7.035896814479807, 2: -7.781398099826851, 3: -7.781398099826851, 4: -7.781398099826851}\n",
            "{0: -6.371381683160362, 1: -7.039762145885296, 2: -7.785263431232341, 3: -7.785263431232341, 4: -7.785263431232341}\n",
            "{0: -6.374860481425302, 1: -7.043240944150238, 2: -7.788742229497283, 3: -7.788742229497283, 4: -7.788742229497283}\n",
            "{0: -6.377991399863749, 1: -7.0463718625886855, 2: -7.791873147935728, 3: -7.791873147935728, 4: -7.791873147935728}\n",
            "{0: -6.380809226458352, 1: -7.049189689183287, 2: -7.794690974530331, 3: -7.794690974530331, 4: -7.794690974530331}\n",
            "{0: -6.383345270393493, 1: -7.051725733118429, 2: -7.797227018465474, 3: -7.797227018465474, 4: -7.797227018465474}\n",
            "{0: -6.385627709935121, 1: -7.0540081726600565, 2: -7.7995094580071, 3: -7.7995094580071, 4: -7.7995094580071}\n",
            "{0: -6.3876819055225855, 1: -7.056062368247522, 2: -7.801563653594566, 3: -7.801563653594566, 4: -7.801563653594566}\n",
            "{0: -6.389530681551305, 1: -7.057911144276241, 2: -7.803412429623284, 3: -7.803412429623284, 4: -7.803412429623284}\n",
            "{0: -6.391194579977151, 1: -7.059575042702088, 2: -7.8050763280491315, 3: -7.8050763280491315, 4: -7.8050763280491315}\n",
            "{0: -6.3926920885604135, 1: -7.061072551285349, 2: -7.806573836632393, 3: -7.806573836632393, 4: -7.806573836632393}\n",
            "{0: -6.394039846285349, 1: -7.062420309010284, 2: -7.807921594357329, 3: -7.807921594357329, 4: -7.807921594357329}\n",
            "{0: -6.3952528282377905, 1: -7.063633290962727, 2: -7.809134576309772, 3: -7.809134576309772, 4: -7.809134576309772}\n",
            "{0: -6.3963445119949895, 1: -7.064724974719925, 2: -7.810226260066969, 3: -7.810226260066969, 4: -7.810226260066969}\n",
            "{0: -6.397327027376468, 1: -7.0657074901014045, 2: -7.811208775448447, 3: -7.811208775448447, 4: -7.811208775448447}\n",
            "{0: -6.398211291219798, 1: -7.066591753944734, 2: -7.812093039291779, 3: -7.812093039291779, 4: -7.812093039291779}\n",
            "{0: -6.399007128678796, 1: -7.067387591403731, 2: -7.812888876750776, 3: -7.812888876750776, 4: -7.812888876750776}\n",
            "{0: -6.399723382391894, 1: -7.068103845116829, 2: -7.813605130463873, 3: -7.813605130463873, 4: -7.813605130463873}\n",
            "{0: -6.400368010733681, 1: -7.0687484734586175, 2: -7.814249758805662, 3: -7.814249758805662, 4: -7.814249758805662}\n",
            "{0: -6.40094817624129, 1: -7.069328638966226, 2: -7.81482992431327, 3: -7.81482992431327, 4: -7.81482992431327}\n",
            "{0: -6.401470325198138, 1: -7.069850787923075, 2: -7.815352073270118, 3: -7.815352073270118, 4: -7.815352073270118}\n",
            "{0: -6.401940259259302, 1: -7.0703207219842374, 2: -7.815822007331281, 3: -7.815822007331281, 4: -7.815822007331281}\n",
            "{0: -6.402363199914348, 1: -7.070743662639284, 2: -7.816244947986329, 3: -7.816244947986329, 4: -7.816244947986329}\n",
            "{0: -6.40274384650389, 1: -7.071124309228827, 2: -7.8166255945758705, 3: -7.8166255945758705, 4: -7.8166255945758705}\n",
            "{0: -6.403086428434479, 1: -7.071466891159415, 2: -7.8169681765064585, 3: -7.8169681765064585, 4: -7.8169681765064585}\n",
            "{0: -6.403394752172009, 1: -7.0717752148969435, 2: -7.817276500243988, 3: -7.817276500243988, 4: -7.817276500243988}\n",
            "{0: -6.403672243535785, 1: -7.07205270626072, 2: -7.817553991607765, 3: -7.817553991607765, 4: -7.817553991607765}\n",
            "{0: -6.4039219857631835, 1: -7.072302448488119, 2: -7.817803733835163, 3: -7.817803733835163, 4: -7.817803733835163}\n",
            "{0: -6.404146753767842, 1: -7.072527216492778, 2: -7.818028501839823, 3: -7.818028501839823, 4: -7.818028501839823}\n",
            "{0: -6.404349044972035, 1: -7.072729507696971, 2: -7.818230793044014, 3: -7.818230793044014, 4: -7.818230793044014}\n",
            "{0: -6.404531107055808, 1: -7.072911569780745, 2: -7.818412855127788, 3: -7.818412855127788, 4: -7.818412855127788}\n",
            "{0: -6.404694962931204, 1: -7.073075425656141, 2: -7.818576711003185, 3: -7.818576711003185, 4: -7.818576711003185}\n",
            "{0: -6.404842433219061, 1: -7.073222895943998, 2: -7.818724181291042, 3: -7.818724181291042, 4: -7.818724181291042}\n",
            "{0: -6.404975156478132, 1: -7.073355619203069, 2: -7.818856904550112, 3: -7.818856904550112, 4: -7.818856904550112}\n",
            "{0: -6.405094607411296, 1: -7.073475070136231, 2: -7.818976355483276, 3: -7.818976355483276, 4: -7.818976355483276}\n",
            "{0: -6.405202113251144, 1: -7.073582575976079, 2: -7.819083861323124, 3: -7.819083861323124, 4: -7.819083861323124}\n",
            "{0: -6.405298868507007, 1: -7.073679331231942, 2: -7.819180616578986, 3: -7.819180616578986, 4: -7.819180616578986}\n",
            "{0: 0, 1: -1.9, 2: -1.0, 3: 8.9, 4: 0}\n",
            "{0: 0, 1: -1.9, 2: -1.0, 3: 8.9, 4: 0}\n",
            "{0: 0, 1: -1.9, 2: -1.0, 3: 8.9, 4: 0}\n",
            "{((0, 1), (0, 1)): 0, ((1, 2), (1, 2)): 0, ((0, 1), (1, 0)): 0.125, ((1, 0), (0, 2)): 0.0, ((0, 2), (1, 2)): 0.75, ((1, 1), (0, 1)): 0.625, ((0, 0), (1, 1)): 0.125, ((1, 1), (0, 0)): 0.125, ((1, 1), (1, 0)): 0.75, ((0, 0), (0, 0)): 0, ((0, 2), (0, 2)): 0, ((1, 1), (1, 1)): 0, ((0, 0), (1, 2)): 0.0, ((1, 0), (0, 1)): 0.125, ((1, 0), (0, 0)): 0.75, ((0, 1), (0, 0)): 0.75, ((0, 1), (1, 1)): 0.625, ((1, 2), (0, 2)): 0.75, ((0, 1), (1, 2)): 0.125, ((1, 2), (0, 1)): 0.125, ((1, 2), (1, 0)): 0.125, ((1, 2), (1, 1)): 0.625, ((1, 0), (1, 0)): 0, ((1, 0), (1, 1)): 0.625, ((0, 2), (0, 1)): 0.625, ((1, 1), (1, 2)): 0.75, ((0, 2), (0, 0)): 0.125, ((0, 0), (0, 2)): 0.125, ((0, 0), (1, 0)): 0.75, ((0, 2), (1, 0)): 0.0, ((0, 2), (1, 1)): 0.125, ((1, 1), (0, 2)): 0.125, ((0, 0), (0, 1)): 0.625, ((1, 0), (1, 2)): 0.125, ((1, 2), (0, 0)): 0.0, ((0, 1), (0, 2)): 0.75}\n",
            "{((0, 1), (0, 1)): 0, ((1, 2), (1, 2)): 0, ((0, 1), (1, 0)): 0.6453125000000001, ((1, 0), (0, 2)): 0.2390625, ((0, 2), (1, 2)): 0.9046875, ((1, 1), (0, 1)): 0.8640625, ((0, 0), (1, 1)): 0.5046875, ((1, 1), (0, 0)): 0.6453125000000001, ((1, 1), (1, 0)): 0.9046875, ((0, 0), (0, 0)): 0, ((0, 2), (0, 2)): 0, ((1, 1), (1, 1)): 0, ((0, 0), (1, 2)): 0.2390625, ((1, 0), (0, 1)): 0.5046875, ((1, 0), (0, 0)): 0.9046875, ((0, 1), (0, 0)): 0.9046875, ((0, 1), (1, 1)): 0.8640625, ((1, 2), (0, 2)): 0.9046875, ((0, 1), (1, 2)): 0.6453125000000001, ((1, 2), (0, 1)): 0.5046875, ((1, 2), (1, 0)): 0.6453125000000001, ((1, 2), (1, 1)): 0.8640625, ((1, 0), (1, 0)): 0, ((1, 0), (1, 1)): 0.8640625, ((0, 2), (0, 1)): 0.8640625, ((1, 1), (1, 2)): 0.9046875, ((0, 2), (0, 0)): 0.6453125000000001, ((0, 0), (0, 2)): 0.6453125000000001, ((0, 0), (1, 0)): 0.9046875, ((0, 2), (1, 0)): 0.2390625, ((0, 2), (1, 1)): 0.5046875, ((1, 1), (0, 2)): 0.6453125000000001, ((0, 0), (0, 1)): 0.8640625, ((1, 0), (1, 2)): 0.6453125000000001, ((1, 2), (0, 0)): 0.2390625, ((0, 1), (0, 2)): 0.9046875}\n",
            "{((0, 1), (0, 1)): 0, ((1, 2), (1, 2)): 0, ((0, 1), (1, 0)): 0.80826171875, ((1, 0), (0, 2)): 0.6345703125, ((0, 2), (1, 2)): 0.948984375, ((1, 1), (0, 1)): 0.92576171875, ((0, 0), (1, 1)): 0.75623046875, ((1, 1), (0, 0)): 0.80826171875, ((1, 1), (1, 0)): 0.948984375, ((0, 0), (0, 0)): 0, ((0, 2), (0, 2)): 0, ((1, 1), (1, 1)): 0, ((0, 0), (1, 2)): 0.6345703125, ((1, 0), (0, 1)): 0.75623046875, ((1, 0), (0, 0)): 0.948984375, ((0, 1), (0, 0)): 0.948984375, ((0, 1), (1, 1)): 0.92576171875, ((1, 2), (0, 2)): 0.948984375, ((0, 1), (1, 2)): 0.80826171875, ((1, 2), (0, 1)): 0.75623046875, ((1, 2), (1, 0)): 0.80826171875, ((1, 2), (1, 1)): 0.92576171875, ((1, 0), (1, 0)): 0, ((1, 0), (1, 1)): 0.92576171875, ((0, 2), (0, 1)): 0.92576171875, ((1, 1), (1, 2)): 0.948984375, ((0, 2), (0, 0)): 0.80826171875, ((0, 0), (0, 2)): 0.80826171875, ((0, 0), (1, 0)): 0.948984375, ((0, 2), (1, 0)): 0.6345703125, ((0, 2), (1, 1)): 0.75623046875, ((1, 1), (0, 2)): 0.80826171875, ((0, 0), (0, 1)): 0.92576171875, ((1, 0), (1, 2)): 0.80826171875, ((1, 2), (0, 0)): 0.6345703125, ((0, 1), (0, 2)): 0.948984375}\n",
            "{((0, 1), (0, 1)): 0, ((1, 2), (1, 2)): 0, ((0, 1), (1, 0)): 0.8564938964843751, ((1, 0), (0, 2)): 0.7564855957031249, ((0, 2), (1, 2)): 0.960908935546875, ((1, 1), (0, 1)): 0.9426696777343749, ((0, 0), (1, 1)): 0.827599853515625, ((1, 1), (0, 0)): 0.8564938964843751, ((1, 1), (1, 0)): 0.960908935546875, ((0, 0), (0, 0)): 0, ((0, 2), (0, 2)): 0, ((1, 1), (1, 1)): 0, ((0, 0), (1, 2)): 0.7564855957031249, ((1, 0), (0, 1)): 0.827599853515625, ((1, 0), (0, 0)): 0.960908935546875, ((0, 1), (0, 0)): 0.960908935546875, ((0, 1), (1, 1)): 0.9426696777343749, ((1, 2), (0, 2)): 0.960908935546875, ((0, 1), (1, 2)): 0.8564938964843751, ((1, 2), (0, 1)): 0.827599853515625, ((1, 2), (1, 0)): 0.8564938964843751, ((1, 2), (1, 1)): 0.9426696777343749, ((1, 0), (1, 0)): 0, ((1, 0), (1, 1)): 0.9426696777343749, ((0, 2), (0, 1)): 0.9426696777343749, ((1, 1), (1, 2)): 0.960908935546875, ((0, 2), (0, 0)): 0.8564938964843751, ((0, 0), (0, 2)): 0.8564938964843751, ((0, 0), (1, 0)): 0.960908935546875, ((0, 2), (1, 0)): 0.7564855957031249, ((0, 2), (1, 1)): 0.827599853515625, ((1, 1), (0, 2)): 0.8564938964843751, ((0, 0), (0, 1)): 0.9426696777343749, ((1, 0), (1, 2)): 0.8564938964843751, ((1, 2), (0, 0)): 0.7564855957031249, ((0, 1), (0, 2)): 0.960908935546875}\n",
            "{((0, 1), (0, 1)): 0, ((1, 2), (1, 2)): 0, ((0, 1), (1, 0)): 0.8699690948486328, ((1, 0), (0, 2)): 0.7922859741210938, ((0, 2), (1, 2)): 0.9641525939941405, ((1, 1), (0, 1)): 0.9472548492431639, ((0, 0), (1, 1)): 0.8479628204345704, ((1, 1), (0, 0)): 0.8699690948486328, ((1, 1), (1, 0)): 0.9641525939941405, ((0, 0), (0, 0)): 0, ((0, 2), (0, 2)): 0, ((1, 1), (1, 1)): 0, ((0, 0), (1, 2)): 0.7922859741210938, ((1, 0), (0, 1)): 0.8479628204345704, ((1, 0), (0, 0)): 0.9641525939941405, ((0, 1), (0, 0)): 0.9641525939941405, ((0, 1), (1, 1)): 0.9472548492431639, ((1, 2), (0, 2)): 0.9641525939941405, ((0, 1), (1, 2)): 0.8699690948486328, ((1, 2), (0, 1)): 0.8479628204345704, ((1, 2), (1, 0)): 0.8699690948486328, ((1, 2), (1, 1)): 0.9472548492431639, ((1, 0), (1, 0)): 0, ((1, 0), (1, 1)): 0.9472548492431639, ((0, 2), (0, 1)): 0.9472548492431639, ((1, 1), (1, 2)): 0.9641525939941405, ((0, 2), (0, 0)): 0.8699690948486328, ((0, 0), (0, 2)): 0.8699690948486328, ((0, 0), (1, 0)): 0.9641525939941405, ((0, 2), (1, 0)): 0.7922859741210938, ((0, 2), (1, 1)): 0.8479628204345704, ((1, 1), (0, 2)): 0.8699690948486328, ((0, 0), (0, 1)): 0.9472548492431639, ((1, 0), (1, 2)): 0.8699690948486328, ((1, 2), (0, 0)): 0.7922859741210938, ((0, 1), (0, 2)): 0.9641525939941405}\n",
            "{((0, 1), (0, 1)): 0, ((1, 2), (1, 2)): 0, ((0, 1), (1, 0)): 0.873674524116516, ((1, 0), (0, 2)): 0.8022624763870239, ((0, 2), (1, 2)): 0.9650333373641967, ((1, 1), (0, 1)): 0.9485005041885375, ((0, 0), (1, 1)): 0.8535738990402221, ((1, 1), (0, 0)): 0.873674524116516, ((1, 1), (1, 0)): 0.9650333373641967, ((0, 0), (0, 0)): 0, ((0, 2), (0, 2)): 0, ((1, 1), (1, 1)): 0, ((0, 0), (1, 2)): 0.8022624763870239, ((1, 0), (0, 1)): 0.8535738990402221, ((1, 0), (0, 0)): 0.9650333373641967, ((0, 1), (0, 0)): 0.9650333373641967, ((0, 1), (1, 1)): 0.9485005041885375, ((1, 2), (0, 2)): 0.9650333373641967, ((0, 1), (1, 2)): 0.873674524116516, ((1, 2), (0, 1)): 0.8535738990402221, ((1, 2), (1, 0)): 0.873674524116516, ((1, 2), (1, 1)): 0.9485005041885375, ((1, 0), (1, 0)): 0, ((1, 0), (1, 1)): 0.9485005041885375, ((0, 2), (0, 1)): 0.9485005041885375, ((1, 1), (1, 2)): 0.9650333373641967, ((0, 2), (0, 0)): 0.873674524116516, ((0, 0), (0, 2)): 0.873674524116516, ((0, 0), (1, 0)): 0.9650333373641967, ((0, 2), (1, 0)): 0.8022624763870239, ((0, 2), (1, 1)): 0.8535738990402221, ((1, 1), (0, 2)): 0.873674524116516, ((0, 0), (0, 1)): 0.9485005041885375, ((1, 0), (1, 2)): 0.873674524116516, ((1, 2), (0, 0)): 0.8022624763870239, ((0, 1), (0, 2)): 0.9650333373641967}\n",
            "{((0, 1), (0, 1)): 0, ((1, 2), (1, 2)): 0, ((0, 1), (1, 0)): 0.8746858866839409, ((1, 0), (0, 2)): 0.805002860953331, ((0, 2), (1, 2)): 0.9652725571746826, ((1, 1), (0, 1)): 0.9488388076281548, ((0, 0), (1, 1)): 0.8551083015322684, ((1, 1), (0, 0)): 0.8746858866839409, ((1, 1), (1, 0)): 0.9652725571746826, ((0, 0), (0, 0)): 0, ((0, 2), (0, 2)): 0, ((1, 1), (1, 1)): 0, ((0, 0), (1, 2)): 0.805002860953331, ((1, 0), (0, 1)): 0.8551083015322684, ((1, 0), (0, 0)): 0.9652725571746826, ((0, 1), (0, 0)): 0.9652725571746826, ((0, 1), (1, 1)): 0.9488388076281548, ((1, 2), (0, 2)): 0.9652725571746826, ((0, 1), (1, 2)): 0.8746858866839409, ((1, 2), (0, 1)): 0.8551083015322684, ((1, 2), (1, 0)): 0.8746858866839409, ((1, 2), (1, 1)): 0.9488388076281548, ((1, 0), (1, 0)): 0, ((1, 0), (1, 1)): 0.9488388076281548, ((0, 2), (0, 1)): 0.9488388076281548, ((1, 1), (1, 2)): 0.9652725571746826, ((0, 2), (0, 0)): 0.8746858866839409, ((0, 0), (0, 2)): 0.8746858866839409, ((0, 0), (1, 0)): 0.9652725571746826, ((0, 2), (1, 0)): 0.805002860953331, ((0, 2), (1, 1)): 0.8551083015322684, ((1, 1), (0, 2)): 0.8746858866839409, ((0, 0), (0, 1)): 0.9488388076281548, ((1, 0), (1, 2)): 0.8746858866839409, ((1, 2), (0, 0)): 0.805002860953331, ((0, 1), (0, 2)): 0.9652725571746826}\n",
            "{((0, 1), (0, 1)): 0, ((1, 2), (1, 2)): 0, ((0, 1), (1, 0)): 0.8749611383448541, ((1, 0), (0, 2)): 0.8057505020519793, ((0, 2), (1, 2)): 0.9653375285403192, ((1, 1), (0, 1)): 0.948930691222471, ((0, 0), (1, 1)): 0.8555261537947236, ((1, 1), (0, 0)): 0.8749611383448541, ((1, 1), (1, 0)): 0.9653375285403192, ((0, 0), (0, 0)): 0, ((0, 2), (0, 2)): 0, ((1, 1), (1, 1)): 0, ((0, 0), (1, 2)): 0.8057505020519793, ((1, 0), (0, 1)): 0.8555261537947236, ((1, 0), (0, 0)): 0.9653375285403192, ((0, 1), (0, 0)): 0.9653375285403192, ((0, 1), (1, 1)): 0.948930691222471, ((1, 2), (0, 2)): 0.9653375285403192, ((0, 1), (1, 2)): 0.8749611383448541, ((1, 2), (0, 1)): 0.8555261537947236, ((1, 2), (1, 0)): 0.8749611383448541, ((1, 2), (1, 1)): 0.948930691222471, ((1, 0), (1, 0)): 0, ((1, 0), (1, 1)): 0.948930691222471, ((0, 2), (0, 1)): 0.948930691222471, ((1, 1), (1, 2)): 0.9653375285403192, ((0, 2), (0, 0)): 0.8749611383448541, ((0, 0), (0, 2)): 0.8749611383448541, ((0, 0), (1, 0)): 0.9653375285403192, ((0, 2), (1, 0)): 0.8057505020519793, ((0, 2), (1, 1)): 0.8555261537947236, ((1, 1), (0, 2)): 0.8749611383448541, ((0, 0), (0, 1)): 0.948930691222471, ((1, 0), (1, 2)): 0.8749611383448541, ((1, 2), (0, 0)): 0.8057505020519793, ((0, 1), (0, 2)): 0.9653375285403192}\n",
            "{((0, 1), (0, 1)): 0, ((1, 2), (1, 2)): 0, ((0, 1), (1, 0)): 0.8750359598285116, ((1, 0), (0, 2)): 0.8059539431060904, ((0, 2), (1, 2)): 0.9653551747233139, ((1, 1), (0, 1)): 0.9489556466840998, ((0, 0), (1, 1)): 0.8556397699402322, ((1, 1), (0, 0)): 0.8750359598285116, ((1, 1), (1, 0)): 0.9653551747233139, ((0, 0), (0, 0)): 0, ((0, 2), (0, 2)): 0, ((1, 1), (1, 1)): 0, ((0, 0), (1, 2)): 0.8059539431060904, ((1, 0), (0, 1)): 0.8556397699402322, ((1, 0), (0, 0)): 0.9653551747233139, ((0, 1), (0, 0)): 0.9653551747233139, ((0, 1), (1, 1)): 0.9489556466840998, ((1, 2), (0, 2)): 0.9653551747233139, ((0, 1), (1, 2)): 0.8750359598285116, ((1, 2), (0, 1)): 0.8556397699402322, ((1, 2), (1, 0)): 0.8750359598285116, ((1, 2), (1, 1)): 0.9489556466840998, ((1, 0), (1, 0)): 0, ((1, 0), (1, 1)): 0.9489556466840998, ((0, 2), (0, 1)): 0.9489556466840998, ((1, 1), (1, 2)): 0.9653551747233139, ((0, 2), (0, 0)): 0.8750359598285116, ((0, 0), (0, 2)): 0.8750359598285116, ((0, 0), (1, 0)): 0.9653551747233139, ((0, 2), (1, 0)): 0.8059539431060904, ((0, 2), (1, 1)): 0.8556397699402322, ((1, 1), (0, 2)): 0.8750359598285116, ((0, 0), (0, 1)): 0.9489556466840998, ((1, 0), (1, 2)): 0.8750359598285116, ((1, 2), (0, 0)): 0.8059539431060904, ((0, 1), (0, 2)): 0.9653551747233139}\n",
            "{((0, 1), (0, 1)): 0, ((1, 2), (1, 2)): 0, ((0, 1), (1, 0)): 0.8750562884189443, ((1, 0), (0, 2)): 0.8060092402925794, ((0, 2), (1, 2)): 0.9653599674083341, ((1, 1), (0, 1)): 0.9489624245647069, ((0, 0), (1, 1)): 0.8556706422212212, ((1, 1), (0, 0)): 0.8750562884189443, ((1, 1), (1, 0)): 0.9653599674083341, ((0, 0), (0, 0)): 0, ((0, 2), (0, 2)): 0, ((1, 1), (1, 1)): 0, ((0, 0), (1, 2)): 0.8060092402925794, ((1, 0), (0, 1)): 0.8556706422212212, ((1, 0), (0, 0)): 0.9653599674083341, ((0, 1), (0, 0)): 0.9653599674083341, ((0, 1), (1, 1)): 0.9489624245647069, ((1, 2), (0, 2)): 0.9653599674083341, ((0, 1), (1, 2)): 0.8750562884189443, ((1, 2), (0, 1)): 0.8556706422212212, ((1, 2), (1, 0)): 0.8750562884189443, ((1, 2), (1, 1)): 0.9489624245647069, ((1, 0), (1, 0)): 0, ((1, 0), (1, 1)): 0.9489624245647069, ((0, 2), (0, 1)): 0.9489624245647069, ((1, 1), (1, 2)): 0.9653599674083341, ((0, 2), (0, 0)): 0.8750562884189443, ((0, 0), (0, 2)): 0.8750562884189443, ((0, 0), (1, 0)): 0.9653599674083341, ((0, 2), (1, 0)): 0.8060092402925794, ((0, 2), (1, 1)): 0.8556706422212212, ((1, 1), (0, 2)): 0.8750562884189443, ((0, 0), (0, 1)): 0.9489624245647069, ((1, 0), (1, 2)): 0.8750562884189443, ((1, 2), (0, 0)): 0.8060092402925794, ((0, 1), (0, 2)): 0.9653599674083341}\n",
            "Tests passed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLINgx0op3T5"
      },
      "source": [
        "### Expectimax Search\n",
        "Complete the implementation of expectimax search for a finite horizon MDP.\n",
        "\n",
        "For reference, our solution is **15** lines of code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fcal0bGp3T6"
      },
      "source": [
        "def expectimax_search(initial_state, mdp, horizon):\n",
        "  \"\"\"Use expectimax search to determine a next action.\n",
        "\n",
        "  Note that we're just computing the single next action to\n",
        "  take, we do not need to store the entire partial V.\n",
        "\n",
        "  Horizon is given as a separate argument so that we can use\n",
        "  expectimax search with receding horizon control, for example,\n",
        "  even if mdp.horizon is inf.\n",
        "\n",
        "  Args:\n",
        "      initial_state: A state in the mdp.\n",
        "      mdp: An MDP.\n",
        "      horizon: An int horizon.\n",
        "\n",
        "  Returns:\n",
        "      action: An action in the mdp.\n",
        "  \"\"\"\n",
        "  def V(next,t,mdp,horizon):\n",
        "    if t == horizon:\n",
        "      return 0\n",
        "    re = -1000\n",
        "    for a in mdp.action_space:\n",
        "      temp = Q(next,a,t,mdp,horizon)\n",
        "      re = max(re,temp)\n",
        "    return re\n",
        "\n",
        "  def Q(s,a,t,mdp,horizon):\n",
        "    result = 0\n",
        "    transition = mdp.get_transition_distribution(s, a)\n",
        "    for next in transition.keys():\n",
        "      p = transition[next]\n",
        "      r = mdp.get_reward(s,a,next)\n",
        "      result += p*(r+mdp.temporal_discount_factor*V(next,t+1,mdp,horizon))\n",
        "    return result\n",
        "\n",
        "  currentmax = -10000\n",
        "  maxAct = None\n",
        "  for action in mdp.action_space:\n",
        "    if Q(initial_state,action,0,mdp,horizon) > currentmax:\n",
        "      maxAct = action\n",
        "      currentmax=Q(initial_state,action,0,mdp,horizon)\n",
        "  return maxAct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxN-zeTtp3T6"
      },
      "source": [
        "Tests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXqdUlEGp3T6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d36a802-5a37-491f-a5d6-bce40dffb2f7"
      },
      "source": [
        "def test1_expectimax_search():\n",
        "    mdp = MarshmallowMDP()\n",
        "    assert expectimax_search((0, True), mdp, mdp.horizon) == \"wait\"\n",
        "    assert expectimax_search((0, True), mdp, 1) == \"eat\"\n",
        "    assert expectimax_search((1, True), mdp, mdp.horizon) == \"eat\"\n",
        "    assert expectimax_search((2, True), mdp, mdp.horizon) == \"eat\"\n",
        "    assert expectimax_search((1, True), mdp, 10) == \"wait\"\n",
        "\n",
        "test1_expectimax_search()\n",
        "def test2_expectimax_search():\n",
        "    mdp = ChaseMDP()\n",
        "    assert expectimax_search(((0, 0), (0, 1)), mdp, 1) == \"right\"\n",
        "    assert expectimax_search(((0, 0), (0, 2)), mdp, 2) == \"right\"\n",
        "    assert expectimax_search(((0, 0), (1, 0)), mdp, 1) == \"down\"\n",
        "    assert expectimax_search(((0, 0), (1, 2)), mdp, 2) in [\"right\", \"down\"]\n",
        "    assert expectimax_search(((1, 2), (0, 0)), mdp, 2) in [\"up\", \"left\"]\n",
        "\n",
        "test2_expectimax_search()\n",
        "print('Tests passed.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tests passed.\n"
          ]
        }
      ]
    }
  ]
}